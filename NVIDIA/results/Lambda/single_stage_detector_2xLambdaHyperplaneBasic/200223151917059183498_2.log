Beginning trial 2 of 2
Gathering sys log on 4029gp-tvrt-1
:::MLL 1582501145.006 submission_benchmark: {"value": "ssd", "metadata": {"file": "mlperf_log_utils.py", "lineno": 176}}
:::MLL 1582501145.007 submission_org: {"value": "NVIDIA", "metadata": {"file": "mlperf_log_utils.py", "lineno": 181}}
WARNING: Log validation: Key "submission_division" is not in known ssd keys.
:::MLL 1582501145.008 submission_division: {"value": "closed", "metadata": {"file": "mlperf_log_utils.py", "lineno": 185}}
:::MLL 1582501145.009 submission_status: {"value": "onprem", "metadata": {"file": "mlperf_log_utils.py", "lineno": 189}}
:::MLL 1582501145.010 submission_platform: {"value": "2xSYS-4029GP-TVRT", "metadata": {"file": "mlperf_log_utils.py", "lineno": 193}}
:::MLL 1582501145.011 submission_entry: {"value": "{'hardware': 'SYS-4029GP-TVRT', 'framework': 'PyTorch NVIDIA Release 19.05', 'power': 'N/A', 'notes': 'N/A', 'interconnect': 'InfiniBand 100 Gb/sec (4X EDR)', 'os': 'Ubuntu 18.04.4 LTS / ', 'libraries': \"{'container_base': 'Ubuntu-16.04', 'openmpi_version': '3.1.3', 'mofed_version': '4.4-1.0.0', 'cuda_version': '10.1.163', 'cuda_driver_version': '418.67', 'nccl_version': '2.4.6', 'cudnn_version': '7.6.0.64', 'cublas_version': '10.2.0.163', 'trt_version': '5.1.5.0', 'dali_version': '0.9.1'}\", 'compilers': 'gcc (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609', 'nodes': \"{'num_nodes': '2', 'cpu': '2x Intel(R) Xeon(R) Gold 6148 CPU @ 2.40GHz', 'num_cores': '40', 'num_vcpus': '80', 'accelerator': 'Tesla V100-SXM2-32GB', 'num_accelerators': '8', 'sys_mem_size': '754 GB', 'sys_storage_type': 'NVMe SSD', 'sys_storage_size': '1x 1.8T + 1x 3.7T', 'cpu_accel_interconnect': 'UPI', 'network_card': '', 'num_network_cards': '0', 'notes': ''}\"}", "metadata": {"file": "mlperf_log_utils.py", "lineno": 197}}
:::MLL 1582501145.011 submission_poc_name: {"value": "Paulius Micikevicius", "metadata": {"file": "mlperf_log_utils.py", "lineno": 201}}
:::MLL 1582501145.012 submission_poc_email: {"value": "pauliusm@nvidia.com", "metadata": {"file": "mlperf_log_utils.py", "lineno": 205}}
Clearing caches
sudo: no tty present and no askpass program specified
sudo: no tty present and no askpass program specified
Launching on node 4029gp-tvrt-0
+ pids+=($!)
+ set +x
Launching on node 4029gp-tvrt-1
+ pids+=($!)
+ set +x
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w 4029gp-tvrt-0
++ eval echo srun --mem=0 -N 1 -n 1 -w '$hostn'
+++ echo srun --mem=0 -N 1 -n 1 -w 4029gp-tvrt-1
+ srun --mem=0 -N 1 -n 1 -w 4029gp-tvrt-0 docker exec -e DGXSYSTEM=2xLambdaHyperplaneBasic -e 'MULTI_NODE= --nnodes=2 --node_rank=0 --master_addr=4029gp-tvrt-0 --master_port=5079' -e SLURM_JOB_ID=352 -e SLURM_NTASKS_PER_NODE=8 cont_352 ./run_and_time.sh
+ srun --mem=0 -N 1 -n 1 -w 4029gp-tvrt-1 docker exec -e DGXSYSTEM=2xLambdaHyperplaneBasic -e 'MULTI_NODE= --nnodes=2 --node_rank=1 --master_addr=4029gp-tvrt-0 --master_port=5079' -e SLURM_JOB_ID=352 -e SLURM_NTASKS_PER_NODE=8 cont_352 ./run_and_time.sh
Run vars: id 352 gpus 8 mparams  --nnodes=2 --node_rank=1 --master_addr=4029gp-tvrt-0 --master_port=5079
Run vars: id 352 gpus 8 mparams  --nnodes=2 --node_rank=0 --master_addr=4029gp-tvrt-0 --master_port=5079
STARTING TIMING RUN AT 2020-02-23 11:39:06 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=2 --node_rank=1 --master_addr=4029gp-tvrt-0 --master_port=5079 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 120 --eval-batch-size 40 --warmup 1250 --bn-group 1 --lr 3.1e-3 --wd 2e-4 --use-nvjpeg --use-roi-decode
STARTING TIMING RUN AT 2020-02-23 11:39:06 PM
running benchmark
+ NUMEPOCHS=80
+ echo 'running benchmark'
+ export DATASET_DIR=/data/coco2017
+ DATASET_DIR=/data/coco2017
+ export TORCH_MODEL_ZOO=/data/torchvision
+ TORCH_MODEL_ZOO=/data/torchvision
+ python -m bind_launch --nsockets_per_node 2 --ncores_per_socket 20 --nproc_per_node 8 --nnodes=2 --node_rank=0 --master_addr=4029gp-tvrt-0 --master_port=5079 train.py --use-fp16 --nhwc --pad-input --jit --delay-allreduce --opt-loss --epochs 80 --warmup-factor 0 --no-save --threshold=0.23 --data /data/coco2017 --evaluation 120000 160000 180000 200000 220000 240000 260000 280000 --batch-size 120 --eval-batch-size 40 --warmup 1250 --bn-group 1 --lr 3.1e-3 --wd 2e-4 --use-nvjpeg --use-roi-decode
:::MLL 1582501149.127 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 1
:::MLL 1582501149.141 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 1
:::MLL 1582501149.156 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 1
:::MLL 1582501149.168 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 1
:::MLL 1582501149.181 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1582501149.182 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1582501149.183 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1582501149.183 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 1
BN group: 1
BN group: 1
BN group: 1
:::MLL 1582501149.189 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1582501149.190 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 1
BN group: 1
:::MLL 1582501149.200 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 1
:::MLL 1582501149.214 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1582501149.215 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 1
:::MLL 1582501149.216 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
:::MLL 1582501149.218 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 1
BN group: 1
BN group: 1
:::MLL 1582501149.223 init_start: {"value": null, "metadata": {"file": "train.py", "lineno": 833}}
BN group: 1
5 Using seed = 148195845
1 Using seed = 148195841
0 Using seed = 148195840
:::MLL 1582501157.912 max_samples: {"value": 1, "metadata": {"file": "utils.py", "lineno": 465}}
3 Using seed = 148195843
7 Using seed = 148195847
6 Using seed = 148195846
4 Using seed = 148195844
10 Using seed = 148195850
14 Using seed = 148195854
12 Using seed = 148195852
15 Using seed = 148195855
13 Using seed = 148195853
11 Using seed = 148195851
8 Using seed = 148195848
9 Using seed = 148195849
2 Using seed = 148195842
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Delaying allreduces to the end of backward()
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
:::MLL 1582501158.632 model_bn_span: {"value": 120, "metadata": {"file": "train.py", "lineno": 480}}
:::MLL 1582501158.632 global_batch_size: {"value": 1920, "metadata": {"file": "train.py", "lineno": 481}}
:::MLL 1582501158.642 opt_base_learning_rate: {"value": 0.185, "metadata": {"file": "train.py", "lineno": 511}}
:::MLL 1582501158.642 opt_weight_decay: {"value": 0.0002, "metadata": {"file": "train.py", "lineno": 513}}
:::MLL 1582501158.642 opt_learning_rate_warmup_steps: {"value": 1250, "metadata": {"file": "train.py", "lineno": 516}}
:::MLL 1582501158.642 opt_learning_rate_warmup_factor: {"value": 0, "metadata": {"file": "train.py", "lineno": 518}}
Delaying allreduces to the end of backward()
epoch nbatch loss
epoch nbatch loss
:::MLL 1582501165.014 init_stop: {"value": null, "metadata": {"file": "train.py", "lineno": 604}}
:::MLL 1582501165.014 run_start: {"value": null, "metadata": {"file": "train.py", "lineno": 610}}
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.46s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.47s)
creating index...
Done (t=0.50s)
creating index...
Done (t=0.51s)
creating index...
time_check a: 1582501166.850534201
time_check a: 1582501166.969344854
time_check b: 1582501170.862610579
time_check b: 1582501170.933100462
:::MLL 1582501171.490 block_start: {"value": null, "metadata": {"first_epoch_num": 1, "epoch_count": 32.74606450292497, "file": "train.py", "lineno": 669}}
:::MLL 1582501171.491 epoch_start: {"value": null, "metadata": {"epoch_num": 1, "file": "train.py", "lineno": 673}}
Iteration:      0, Loss function: 22.487, Average Loss: 0.022, avg. samples / sec: 145.43
Iteration:      0, Loss function: 22.314, Average Loss: 0.022, avg. samples / sec: 143.61
Iteration:     20, Loss function: 20.699, Average Loss: 0.441, avg. samples / sec: 6883.52
Iteration:     20, Loss function: 20.605, Average Loss: 0.440, avg. samples / sec: 6721.44
Iteration:     40, Loss function: 17.427, Average Loss: 0.825, avg. samples / sec: 7811.94
Iteration:     40, Loss function: 17.163, Average Loss: 0.825, avg. samples / sec: 7790.35
Iteration:     60, Loss function: 13.110, Average Loss: 1.086, avg. samples / sec: 8174.08
Iteration:     60, Loss function: 13.135, Average Loss: 1.085, avg. samples / sec: 8189.83
:::MLL 1582501188.254 epoch_stop: {"value": null, "metadata": {"epoch_num": 1, "file": "train.py", "lineno": 819}}
:::MLL 1582501188.254 epoch_start: {"value": null, "metadata": {"epoch_num": 2, "file": "train.py", "lineno": 673}}
Iteration:     80, Loss function: 10.206, Average Loss: 1.284, avg. samples / sec: 8233.94
Iteration:     80, Loss function: 10.412, Average Loss: 1.285, avg. samples / sec: 8230.74
Iteration:    100, Loss function: 9.336, Average Loss: 1.450, avg. samples / sec: 8199.35
Iteration:    100, Loss function: 9.181, Average Loss: 1.449, avg. samples / sec: 8183.39
Iteration:    120, Loss function: 9.041, Average Loss: 1.601, avg. samples / sec: 8253.15
Iteration:    120, Loss function: 8.911, Average Loss: 1.602, avg. samples / sec: 8221.95
:::MLL 1582501202.488 epoch_stop: {"value": null, "metadata": {"epoch_num": 2, "file": "train.py", "lineno": 819}}
:::MLL 1582501202.489 epoch_start: {"value": null, "metadata": {"epoch_num": 3, "file": "train.py", "lineno": 673}}
Iteration:    140, Loss function: 8.907, Average Loss: 1.747, avg. samples / sec: 8260.13
Iteration:    140, Loss function: 8.815, Average Loss: 1.747, avg. samples / sec: 8277.27
Iteration:    160, Loss function: 8.474, Average Loss: 1.886, avg. samples / sec: 8414.23
Iteration:    160, Loss function: 8.674, Average Loss: 1.887, avg. samples / sec: 8413.75
Iteration:    180, Loss function: 8.066, Average Loss: 2.016, avg. samples / sec: 8359.55
Iteration:    180, Loss function: 8.243, Average Loss: 2.015, avg. samples / sec: 8358.96
:::MLL 1582501216.496 epoch_stop: {"value": null, "metadata": {"epoch_num": 3, "file": "train.py", "lineno": 819}}
:::MLL 1582501216.497 epoch_start: {"value": null, "metadata": {"epoch_num": 4, "file": "train.py", "lineno": 673}}
Iteration:    200, Loss function: 8.708, Average Loss: 2.144, avg. samples / sec: 8281.97
Iteration:    200, Loss function: 8.710, Average Loss: 2.142, avg. samples / sec: 8282.12
Iteration:    220, Loss function: 7.920, Average Loss: 2.264, avg. samples / sec: 8444.08
Iteration:    220, Loss function: 7.922, Average Loss: 2.263, avg. samples / sec: 8444.18
Iteration:    240, Loss function: 7.617, Average Loss: 2.373, avg. samples / sec: 8490.09
Iteration:    240, Loss function: 7.690, Average Loss: 2.371, avg. samples / sec: 8488.97
:::MLL 1582501230.403 epoch_stop: {"value": null, "metadata": {"epoch_num": 4, "file": "train.py", "lineno": 819}}
:::MLL 1582501230.403 epoch_start: {"value": null, "metadata": {"epoch_num": 5, "file": "train.py", "lineno": 673}}
Iteration:    260, Loss function: 7.517, Average Loss: 2.478, avg. samples / sec: 8459.17
Iteration:    260, Loss function: 7.761, Average Loss: 2.481, avg. samples / sec: 8457.90
Iteration:    280, Loss function: 7.377, Average Loss: 2.582, avg. samples / sec: 8327.08
Iteration:    280, Loss function: 7.401, Average Loss: 2.581, avg. samples / sec: 8326.18
Iteration:    300, Loss function: 7.292, Average Loss: 2.675, avg. samples / sec: 8479.49
Iteration:    300, Loss function: 7.170, Average Loss: 2.676, avg. samples / sec: 8471.84
:::MLL 1582501244.303 epoch_stop: {"value": null, "metadata": {"epoch_num": 5, "file": "train.py", "lineno": 819}}
:::MLL 1582501244.303 epoch_start: {"value": null, "metadata": {"epoch_num": 6, "file": "train.py", "lineno": 673}}
Iteration:    320, Loss function: 7.191, Average Loss: 2.767, avg. samples / sec: 8381.85
Iteration:    320, Loss function: 7.247, Average Loss: 2.766, avg. samples / sec: 8374.95
Iteration:    340, Loss function: 7.315, Average Loss: 2.853, avg. samples / sec: 8471.68
Iteration:    340, Loss function: 7.095, Average Loss: 2.853, avg. samples / sec: 8471.38
Iteration:    360, Loss function: 7.133, Average Loss: 2.933, avg. samples / sec: 8431.95
Iteration:    360, Loss function: 6.966, Average Loss: 2.934, avg. samples / sec: 8431.65
:::MLL 1582501258.201 epoch_stop: {"value": null, "metadata": {"epoch_num": 6, "file": "train.py", "lineno": 819}}
:::MLL 1582501258.201 epoch_start: {"value": null, "metadata": {"epoch_num": 7, "file": "train.py", "lineno": 673}}
Iteration:    380, Loss function: 6.882, Average Loss: 3.013, avg. samples / sec: 8479.63
Iteration:    380, Loss function: 6.793, Average Loss: 3.013, avg. samples / sec: 8478.95
Iteration:    400, Loss function: 6.853, Average Loss: 3.089, avg. samples / sec: 8319.05
Iteration:    400, Loss function: 7.281, Average Loss: 3.091, avg. samples / sec: 8316.77
Iteration:    420, Loss function: 6.678, Average Loss: 3.159, avg. samples / sec: 8410.33
Iteration:    420, Loss function: 6.432, Average Loss: 3.160, avg. samples / sec: 8410.99
:::MLL 1582501272.146 epoch_stop: {"value": null, "metadata": {"epoch_num": 7, "file": "train.py", "lineno": 819}}
:::MLL 1582501272.146 epoch_start: {"value": null, "metadata": {"epoch_num": 8, "file": "train.py", "lineno": 673}}
Iteration:    440, Loss function: 6.501, Average Loss: 3.226, avg. samples / sec: 8375.64
Iteration:    440, Loss function: 6.474, Average Loss: 3.228, avg. samples / sec: 8374.30
Iteration:    460, Loss function: 6.310, Average Loss: 3.294, avg. samples / sec: 8455.17
Iteration:    460, Loss function: 6.229, Average Loss: 3.290, avg. samples / sec: 8452.52
Iteration:    480, Loss function: 6.061, Average Loss: 3.356, avg. samples / sec: 8522.50
Iteration:    480, Loss function: 6.124, Average Loss: 3.350, avg. samples / sec: 8520.51
:::MLL 1582501286.013 epoch_stop: {"value": null, "metadata": {"epoch_num": 8, "file": "train.py", "lineno": 819}}
:::MLL 1582501286.014 epoch_start: {"value": null, "metadata": {"epoch_num": 9, "file": "train.py", "lineno": 673}}
Iteration:    500, Loss function: 6.664, Average Loss: 3.413, avg. samples / sec: 8362.17
Iteration:    500, Loss function: 6.558, Average Loss: 3.408, avg. samples / sec: 8362.97
Iteration:    520, Loss function: 6.085, Average Loss: 3.464, avg. samples / sec: 8487.90
Iteration:    520, Loss function: 6.117, Average Loss: 3.469, avg. samples / sec: 8484.44
Iteration:    540, Loss function: 5.519, Average Loss: 3.515, avg. samples / sec: 8469.84
Iteration:    540, Loss function: 5.792, Average Loss: 3.519, avg. samples / sec: 8470.15
:::MLL 1582501299.885 epoch_stop: {"value": null, "metadata": {"epoch_num": 9, "file": "train.py", "lineno": 819}}
:::MLL 1582501299.885 epoch_start: {"value": null, "metadata": {"epoch_num": 10, "file": "train.py", "lineno": 673}}
Iteration:    560, Loss function: 6.187, Average Loss: 3.562, avg. samples / sec: 8468.13
Iteration:    560, Loss function: 6.272, Average Loss: 3.567, avg. samples / sec: 8469.10
Iteration:    580, Loss function: 5.606, Average Loss: 3.611, avg. samples / sec: 8506.08
Iteration:    580, Loss function: 5.936, Average Loss: 3.614, avg. samples / sec: 8495.70
Iteration:    600, Loss function: 5.893, Average Loss: 3.657, avg. samples / sec: 8460.41
Iteration:    600, Loss function: 5.882, Average Loss: 3.654, avg. samples / sec: 8449.38
:::MLL 1582501313.697 epoch_stop: {"value": null, "metadata": {"epoch_num": 10, "file": "train.py", "lineno": 819}}
:::MLL 1582501313.698 epoch_start: {"value": null, "metadata": {"epoch_num": 11, "file": "train.py", "lineno": 673}}
Iteration:    620, Loss function: 6.305, Average Loss: 3.700, avg. samples / sec: 8496.09
Iteration:    620, Loss function: 6.264, Average Loss: 3.696, avg. samples / sec: 8495.06
Iteration:    640, Loss function: 5.679, Average Loss: 3.743, avg. samples / sec: 8460.31
Iteration:    640, Loss function: 5.600, Average Loss: 3.740, avg. samples / sec: 8459.52
Iteration:    660, Loss function: 5.338, Average Loss: 3.775, avg. samples / sec: 8509.60
Iteration:    660, Loss function: 5.204, Average Loss: 3.778, avg. samples / sec: 8506.90
:::MLL 1582501327.493 epoch_stop: {"value": null, "metadata": {"epoch_num": 11, "file": "train.py", "lineno": 819}}
:::MLL 1582501327.493 epoch_start: {"value": null, "metadata": {"epoch_num": 12, "file": "train.py", "lineno": 673}}
Iteration:    680, Loss function: 5.421, Average Loss: 3.811, avg. samples / sec: 8479.91
Iteration:    680, Loss function: 5.327, Average Loss: 3.814, avg. samples / sec: 8479.15
Iteration:    700, Loss function: 5.214, Average Loss: 3.845, avg. samples / sec: 8443.31
Iteration:    700, Loss function: 5.200, Average Loss: 3.843, avg. samples / sec: 8441.34
Iteration:    720, Loss function: 5.474, Average Loss: 3.876, avg. samples / sec: 8403.11
Iteration:    720, Loss function: 5.201, Average Loss: 3.875, avg. samples / sec: 8400.93
:::MLL 1582501341.365 epoch_stop: {"value": null, "metadata": {"epoch_num": 12, "file": "train.py", "lineno": 819}}
:::MLL 1582501341.365 epoch_start: {"value": null, "metadata": {"epoch_num": 13, "file": "train.py", "lineno": 673}}
Iteration:    740, Loss function: 5.210, Average Loss: 3.908, avg. samples / sec: 8485.28
Iteration:    740, Loss function: 5.512, Average Loss: 3.908, avg. samples / sec: 8485.81
Iteration:    760, Loss function: 5.262, Average Loss: 3.936, avg. samples / sec: 8529.04
Iteration:    760, Loss function: 5.239, Average Loss: 3.935, avg. samples / sec: 8530.95
Iteration:    780, Loss function: 5.720, Average Loss: 3.964, avg. samples / sec: 8430.61
Iteration:    780, Loss function: 5.548, Average Loss: 3.965, avg. samples / sec: 8430.23
:::MLL 1582501355.167 epoch_stop: {"value": null, "metadata": {"epoch_num": 13, "file": "train.py", "lineno": 819}}
:::MLL 1582501355.168 epoch_start: {"value": null, "metadata": {"epoch_num": 14, "file": "train.py", "lineno": 673}}
Iteration:    800, Loss function: 5.310, Average Loss: 3.992, avg. samples / sec: 8486.25
Iteration:    800, Loss function: 5.251, Average Loss: 3.992, avg. samples / sec: 8485.91
Iteration:    820, Loss function: 5.104, Average Loss: 4.016, avg. samples / sec: 8541.01
Iteration:    820, Loss function: 5.108, Average Loss: 4.015, avg. samples / sec: 8538.56
Iteration:    840, Loss function: 4.868, Average Loss: 4.037, avg. samples / sec: 8434.54
Iteration:    840, Loss function: 5.298, Average Loss: 4.037, avg. samples / sec: 8436.42
:::MLL 1582501369.228 epoch_stop: {"value": null, "metadata": {"epoch_num": 14, "file": "train.py", "lineno": 819}}
:::MLL 1582501369.228 epoch_start: {"value": null, "metadata": {"epoch_num": 15, "file": "train.py", "lineno": 673}}
Iteration:    860, Loss function: 5.457, Average Loss: 4.060, avg. samples / sec: 8432.28
Iteration:    860, Loss function: 5.442, Average Loss: 4.061, avg. samples / sec: 8432.02
Iteration:    880, Loss function: 5.173, Average Loss: 4.082, avg. samples / sec: 8431.92
Iteration:    880, Loss function: 4.896, Average Loss: 4.083, avg. samples / sec: 8429.95
Iteration:    900, Loss function: 5.252, Average Loss: 4.099, avg. samples / sec: 8436.24
Iteration:    900, Loss function: 5.126, Average Loss: 4.100, avg. samples / sec: 8433.67
:::MLL 1582501383.090 epoch_stop: {"value": null, "metadata": {"epoch_num": 15, "file": "train.py", "lineno": 819}}
:::MLL 1582501383.091 epoch_start: {"value": null, "metadata": {"epoch_num": 16, "file": "train.py", "lineno": 673}}
Iteration:    920, Loss function: 5.346, Average Loss: 4.123, avg. samples / sec: 8491.15
Iteration:    920, Loss function: 5.096, Average Loss: 4.119, avg. samples / sec: 8489.91
Iteration:    940, Loss function: 4.982, Average Loss: 4.143, avg. samples / sec: 8447.58
Iteration:    940, Loss function: 5.026, Average Loss: 4.139, avg. samples / sec: 8448.11
Iteration:    960, Loss function: 4.974, Average Loss: 4.158, avg. samples / sec: 8460.53
Iteration:    960, Loss function: 5.034, Average Loss: 4.155, avg. samples / sec: 8460.84
:::MLL 1582501396.923 epoch_stop: {"value": null, "metadata": {"epoch_num": 16, "file": "train.py", "lineno": 819}}
:::MLL 1582501396.924 epoch_start: {"value": null, "metadata": {"epoch_num": 17, "file": "train.py", "lineno": 673}}
Iteration:    980, Loss function: 4.817, Average Loss: 4.174, avg. samples / sec: 8486.09
Iteration:    980, Loss function: 4.937, Average Loss: 4.169, avg. samples / sec: 8485.83
Iteration:   1000, Loss function: 4.887, Average Loss: 4.187, avg. samples / sec: 8494.52
Iteration:   1000, Loss function: 4.755, Average Loss: 4.182, avg. samples / sec: 8495.04
Iteration:   1020, Loss function: 4.657, Average Loss: 4.199, avg. samples / sec: 8469.53
Iteration:   1020, Loss function: 4.942, Average Loss: 4.195, avg. samples / sec: 8467.89
:::MLL 1582501410.724 epoch_stop: {"value": null, "metadata": {"epoch_num": 17, "file": "train.py", "lineno": 819}}
:::MLL 1582501410.725 epoch_start: {"value": null, "metadata": {"epoch_num": 18, "file": "train.py", "lineno": 673}}
Iteration:   1040, Loss function: 4.757, Average Loss: 4.215, avg. samples / sec: 8496.68
Iteration:   1040, Loss function: 5.190, Average Loss: 4.211, avg. samples / sec: 8497.98
Iteration:   1060, Loss function: 4.800, Average Loss: 4.228, avg. samples / sec: 8467.28
Iteration:   1060, Loss function: 4.648, Average Loss: 4.222, avg. samples / sec: 8466.04
Iteration:   1080, Loss function: 4.965, Average Loss: 4.240, avg. samples / sec: 8429.03
Iteration:   1080, Loss function: 4.831, Average Loss: 4.236, avg. samples / sec: 8430.73
:::MLL 1582501424.550 epoch_stop: {"value": null, "metadata": {"epoch_num": 18, "file": "train.py", "lineno": 819}}
:::MLL 1582501424.550 epoch_start: {"value": null, "metadata": {"epoch_num": 19, "file": "train.py", "lineno": 673}}
Iteration:   1100, Loss function: 5.006, Average Loss: 4.249, avg. samples / sec: 8519.89
Iteration:   1100, Loss function: 4.746, Average Loss: 4.254, avg. samples / sec: 8517.94
Iteration:   1120, Loss function: 4.719, Average Loss: 4.257, avg. samples / sec: 8492.08
Iteration:   1120, Loss function: 4.884, Average Loss: 4.263, avg. samples / sec: 8494.08
Iteration:   1140, Loss function: 4.636, Average Loss: 4.272, avg. samples / sec: 8508.63
Iteration:   1140, Loss function: 4.657, Average Loss: 4.267, avg. samples / sec: 8507.55
Iteration:   1160, Loss function: 4.936, Average Loss: 4.283, avg. samples / sec: 8508.83
Iteration:   1160, Loss function: 5.019, Average Loss: 4.276, avg. samples / sec: 8508.93
:::MLL 1582501438.328 epoch_stop: {"value": null, "metadata": {"epoch_num": 19, "file": "train.py", "lineno": 819}}
:::MLL 1582501438.328 epoch_start: {"value": null, "metadata": {"epoch_num": 20, "file": "train.py", "lineno": 673}}
Iteration:   1180, Loss function: 4.810, Average Loss: 4.294, avg. samples / sec: 8508.17
Iteration:   1180, Loss function: 4.948, Average Loss: 4.285, avg. samples / sec: 8506.94
Iteration:   1200, Loss function: 4.471, Average Loss: 4.302, avg. samples / sec: 8454.09
Iteration:   1200, Loss function: 4.772, Average Loss: 4.293, avg. samples / sec: 8455.62
Iteration:   1220, Loss function: 4.662, Average Loss: 4.310, avg. samples / sec: 8519.50
Iteration:   1220, Loss function: 4.963, Average Loss: 4.302, avg. samples / sec: 8518.96
:::MLL 1582501452.115 epoch_stop: {"value": null, "metadata": {"epoch_num": 20, "file": "train.py", "lineno": 819}}
:::MLL 1582501452.115 epoch_start: {"value": null, "metadata": {"epoch_num": 21, "file": "train.py", "lineno": 673}}
Iteration:   1240, Loss function: 4.743, Average Loss: 4.309, avg. samples / sec: 8498.14
Iteration:   1240, Loss function: 4.501, Average Loss: 4.316, avg. samples / sec: 8495.79
Iteration:   1260, Loss function: 5.070, Average Loss: 4.327, avg. samples / sec: 8508.35
Iteration:   1260, Loss function: 4.860, Average Loss: 4.321, avg. samples / sec: 8506.30
Iteration:   1280, Loss function: 4.760, Average Loss: 4.334, avg. samples / sec: 8450.53
Iteration:   1280, Loss function: 4.842, Average Loss: 4.328, avg. samples / sec: 8451.16
:::MLL 1582501465.915 epoch_stop: {"value": null, "metadata": {"epoch_num": 21, "file": "train.py", "lineno": 819}}
:::MLL 1582501465.916 epoch_start: {"value": null, "metadata": {"epoch_num": 22, "file": "train.py", "lineno": 673}}
Iteration:   1300, Loss function: 4.674, Average Loss: 4.333, avg. samples / sec: 8520.02
Iteration:   1300, Loss function: 4.509, Average Loss: 4.339, avg. samples / sec: 8518.12
Iteration:   1320, Loss function: 4.149, Average Loss: 4.343, avg. samples / sec: 8517.95
Iteration:   1320, Loss function: 4.361, Average Loss: 4.338, avg. samples / sec: 8515.47
Iteration:   1340, Loss function: 4.400, Average Loss: 4.345, avg. samples / sec: 8485.31
Iteration:   1340, Loss function: 4.587, Average Loss: 4.342, avg. samples / sec: 8485.27
:::MLL 1582501479.681 epoch_stop: {"value": null, "metadata": {"epoch_num": 22, "file": "train.py", "lineno": 819}}
:::MLL 1582501479.682 epoch_start: {"value": null, "metadata": {"epoch_num": 23, "file": "train.py", "lineno": 673}}
Iteration:   1360, Loss function: 4.340, Average Loss: 4.349, avg. samples / sec: 8403.11
Iteration:   1360, Loss function: 4.528, Average Loss: 4.346, avg. samples / sec: 8401.06
Iteration:   1380, Loss function: 4.486, Average Loss: 4.352, avg. samples / sec: 8505.97
Iteration:   1380, Loss function: 4.486, Average Loss: 4.348, avg. samples / sec: 8506.16
Iteration:   1400, Loss function: 4.456, Average Loss: 4.351, avg. samples / sec: 8482.09
Iteration:   1400, Loss function: 4.640, Average Loss: 4.355, avg. samples / sec: 8478.51
:::MLL 1582501493.522 epoch_stop: {"value": null, "metadata": {"epoch_num": 23, "file": "train.py", "lineno": 819}}
:::MLL 1582501493.522 epoch_start: {"value": null, "metadata": {"epoch_num": 24, "file": "train.py", "lineno": 673}}
Iteration:   1420, Loss function: 4.211, Average Loss: 4.356, avg. samples / sec: 8508.01
Iteration:   1420, Loss function: 4.120, Average Loss: 4.352, avg. samples / sec: 8505.61
Iteration:   1440, Loss function: 4.483, Average Loss: 4.360, avg. samples / sec: 8484.74
Iteration:   1440, Loss function: 4.473, Average Loss: 4.355, avg. samples / sec: 8485.08
Iteration:   1460, Loss function: 4.607, Average Loss: 4.356, avg. samples / sec: 8468.11
Iteration:   1460, Loss function: 4.569, Average Loss: 4.361, avg. samples / sec: 8465.77
:::MLL 1582501507.323 epoch_stop: {"value": null, "metadata": {"epoch_num": 24, "file": "train.py", "lineno": 819}}
:::MLL 1582501507.323 epoch_start: {"value": null, "metadata": {"epoch_num": 25, "file": "train.py", "lineno": 673}}
Iteration:   1480, Loss function: 4.535, Average Loss: 4.362, avg. samples / sec: 8494.29
Iteration:   1480, Loss function: 4.386, Average Loss: 4.359, avg. samples / sec: 8485.83
Iteration:   1500, Loss function: 4.125, Average Loss: 4.362, avg. samples / sec: 8532.85
Iteration:   1500, Loss function: 4.747, Average Loss: 4.360, avg. samples / sec: 8539.54
Iteration:   1520, Loss function: 4.252, Average Loss: 4.361, avg. samples / sec: 8448.36
Iteration:   1520, Loss function: 4.440, Average Loss: 4.360, avg. samples / sec: 8446.65
:::MLL 1582501521.140 epoch_stop: {"value": null, "metadata": {"epoch_num": 25, "file": "train.py", "lineno": 819}}
:::MLL 1582501521.141 epoch_start: {"value": null, "metadata": {"epoch_num": 26, "file": "train.py", "lineno": 673}}
Iteration:   1540, Loss function: 4.105, Average Loss: 4.359, avg. samples / sec: 8444.41
Iteration:   1540, Loss function: 4.231, Average Loss: 4.361, avg. samples / sec: 8442.32
Iteration:   1560, Loss function: 4.685, Average Loss: 4.362, avg. samples / sec: 8519.55
Iteration:   1560, Loss function: 4.772, Average Loss: 4.361, avg. samples / sec: 8517.50
Iteration:   1580, Loss function: 4.615, Average Loss: 4.364, avg. samples / sec: 8487.46
Iteration:   1580, Loss function: 4.188, Average Loss: 4.363, avg. samples / sec: 8486.96
:::MLL 1582501534.932 epoch_stop: {"value": null, "metadata": {"epoch_num": 26, "file": "train.py", "lineno": 819}}
:::MLL 1582501534.933 epoch_start: {"value": null, "metadata": {"epoch_num": 27, "file": "train.py", "lineno": 673}}
Iteration:   1600, Loss function: 4.147, Average Loss: 4.362, avg. samples / sec: 8481.78
Iteration:   1600, Loss function: 4.526, Average Loss: 4.363, avg. samples / sec: 8481.77
Iteration:   1620, Loss function: 4.316, Average Loss: 4.361, avg. samples / sec: 8518.98
Iteration:   1620, Loss function: 4.401, Average Loss: 4.363, avg. samples / sec: 8519.29
Iteration:   1640, Loss function: 3.980, Average Loss: 4.360, avg. samples / sec: 8513.83
Iteration:   1640, Loss function: 4.168, Average Loss: 4.362, avg. samples / sec: 8514.74
:::MLL 1582501548.933 epoch_stop: {"value": null, "metadata": {"epoch_num": 27, "file": "train.py", "lineno": 819}}
:::MLL 1582501548.933 epoch_start: {"value": null, "metadata": {"epoch_num": 28, "file": "train.py", "lineno": 673}}
Iteration:   1660, Loss function: 4.469, Average Loss: 4.363, avg. samples / sec: 8473.42
Iteration:   1660, Loss function: 4.205, Average Loss: 4.360, avg. samples / sec: 8472.11
Iteration:   1680, Loss function: 4.411, Average Loss: 4.362, avg. samples / sec: 8507.66
Iteration:   1680, Loss function: 4.086, Average Loss: 4.359, avg. samples / sec: 8507.63
Iteration:   1700, Loss function: 4.512, Average Loss: 4.357, avg. samples / sec: 8531.53
Iteration:   1700, Loss function: 4.203, Average Loss: 4.361, avg. samples / sec: 8528.56
:::MLL 1582501562.690 epoch_stop: {"value": null, "metadata": {"epoch_num": 28, "file": "train.py", "lineno": 819}}
:::MLL 1582501562.690 epoch_start: {"value": null, "metadata": {"epoch_num": 29, "file": "train.py", "lineno": 673}}
Iteration:   1720, Loss function: 4.118, Average Loss: 4.355, avg. samples / sec: 8502.74
Iteration:   1720, Loss function: 4.016, Average Loss: 4.359, avg. samples / sec: 8504.70
Iteration:   1740, Loss function: 4.100, Average Loss: 4.356, avg. samples / sec: 8510.80
Iteration:   1740, Loss function: 4.349, Average Loss: 4.353, avg. samples / sec: 8508.86
Iteration:   1760, Loss function: 4.341, Average Loss: 4.354, avg. samples / sec: 8504.53
Iteration:   1760, Loss function: 4.544, Average Loss: 4.351, avg. samples / sec: 8505.61
:::MLL 1582501576.463 epoch_stop: {"value": null, "metadata": {"epoch_num": 29, "file": "train.py", "lineno": 819}}
:::MLL 1582501576.463 epoch_start: {"value": null, "metadata": {"epoch_num": 30, "file": "train.py", "lineno": 673}}
Iteration:   1780, Loss function: 4.323, Average Loss: 4.347, avg. samples / sec: 8477.70
Iteration:   1780, Loss function: 4.262, Average Loss: 4.351, avg. samples / sec: 8475.09
Iteration:   1800, Loss function: 4.298, Average Loss: 4.345, avg. samples / sec: 8495.93
Iteration:   1800, Loss function: 4.297, Average Loss: 4.347, avg. samples / sec: 8497.42
Iteration:   1820, Loss function: 4.027, Average Loss: 4.341, avg. samples / sec: 8501.57
Iteration:   1820, Loss function: 4.115, Average Loss: 4.345, avg. samples / sec: 8501.53
:::MLL 1582501590.254 epoch_stop: {"value": null, "metadata": {"epoch_num": 30, "file": "train.py", "lineno": 819}}
:::MLL 1582501590.254 epoch_start: {"value": null, "metadata": {"epoch_num": 31, "file": "train.py", "lineno": 673}}
Iteration:   1840, Loss function: 4.137, Average Loss: 4.340, avg. samples / sec: 8492.56
Iteration:   1840, Loss function: 4.332, Average Loss: 4.343, avg. samples / sec: 8491.60
Iteration:   1860, Loss function: 4.005, Average Loss: 4.340, avg. samples / sec: 8517.21
Iteration:   1860, Loss function: 4.067, Average Loss: 4.336, avg. samples / sec: 8515.03
Iteration:   1880, Loss function: 4.450, Average Loss: 4.338, avg. samples / sec: 8475.12
Iteration:   1880, Loss function: 4.352, Average Loss: 4.333, avg. samples / sec: 8474.38
:::MLL 1582501604.045 epoch_stop: {"value": null, "metadata": {"epoch_num": 31, "file": "train.py", "lineno": 819}}
:::MLL 1582501604.046 epoch_start: {"value": null, "metadata": {"epoch_num": 32, "file": "train.py", "lineno": 673}}
Iteration:   1900, Loss function: 4.264, Average Loss: 4.335, avg. samples / sec: 8494.31
Iteration:   1900, Loss function: 4.118, Average Loss: 4.329, avg. samples / sec: 8495.47
Iteration:   1920, Loss function: 3.870, Average Loss: 4.324, avg. samples / sec: 8524.26
Iteration:   1920, Loss function: 3.993, Average Loss: 4.331, avg. samples / sec: 8520.98
Iteration:   1940, Loss function: 4.291, Average Loss: 4.321, avg. samples / sec: 8502.91
Iteration:   1940, Loss function: 4.380, Average Loss: 4.327, avg. samples / sec: 8504.89
:::MLL 1582501617.810 epoch_stop: {"value": null, "metadata": {"epoch_num": 32, "file": "train.py", "lineno": 819}}
:::MLL 1582501617.810 epoch_start: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 673}}
Iteration:   1960, Loss function: 3.934, Average Loss: 4.325, avg. samples / sec: 8486.26
Iteration:   1960, Loss function: 3.960, Average Loss: 4.319, avg. samples / sec: 8484.57
Iteration:   1980, Loss function: 4.315, Average Loss: 4.322, avg. samples / sec: 8516.33
Iteration:   1980, Loss function: 4.440, Average Loss: 4.319, avg. samples / sec: 8517.54
Iteration:   2000, Loss function: 4.202, Average Loss: 4.318, avg. samples / sec: 8518.59
Iteration:   2000, Loss function: 4.318, Average Loss: 4.315, avg. samples / sec: 8518.66
:::MLL 1582501628.195 eval_start: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 276}}
Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 2/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 3/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 4/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 5/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 6/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 7/Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 1/8Parsing batch: 2/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 3/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 4/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 5/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 6/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 7/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Predicting Ended, total time: 3.46 s
8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Predicting Ended, total time: 3.46 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.44s)
DONE (t=0.44s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.45s)
DONE (t=0.50s)
DONE (t=2.85s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.15610
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.29347
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.15216
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.03751
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.16453
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.25535
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.16957
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.24980
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.26437
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.06659
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.27947
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.41443
Current AP: 0.15610 AP goal: 0.23000
:::MLL 1582501635.003 eval_accuracy: {"value": 0.15610452913667786, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 389}}
:::MLL 1582501635.023 eval_stop: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 392}}
:::MLL 1582501635.029 block_stop: {"value": null, "metadata": {"first_epoch_num": 1, "file": "train.py", "lineno": 804}}
:::MLL 1582501635.030 block_start: {"value": null, "metadata": {"first_epoch_num": 33, "epoch_count": 10.915354834308324, "file": "train.py", "lineno": 813}}
:::MLL 1582501638.784 epoch_stop: {"value": null, "metadata": {"epoch_num": 33, "file": "train.py", "lineno": 819}}
:::MLL 1582501638.784 epoch_start: {"value": null, "metadata": {"epoch_num": 34, "file": "train.py", "lineno": 673}}
Iteration:   2020, Loss function: 4.149, Average Loss: 4.311, avg. samples / sec: 3275.85
Iteration:   2020, Loss function: 4.139, Average Loss: 4.314, avg. samples / sec: 3275.35
Iteration:   2040, Loss function: 4.278, Average Loss: 4.308, avg. samples / sec: 8477.99
Iteration:   2040, Loss function: 4.210, Average Loss: 4.309, avg. samples / sec: 8477.76
Iteration:   2060, Loss function: 4.030, Average Loss: 4.305, avg. samples / sec: 8477.79
Iteration:   2060, Loss function: 4.148, Average Loss: 4.307, avg. samples / sec: 8478.93
:::MLL 1582501652.575 epoch_stop: {"value": null, "metadata": {"epoch_num": 34, "file": "train.py", "lineno": 819}}
:::MLL 1582501652.576 epoch_start: {"value": null, "metadata": {"epoch_num": 35, "file": "train.py", "lineno": 673}}
Iteration:   2080, Loss function: 3.979, Average Loss: 4.304, avg. samples / sec: 8512.55
Iteration:   2080, Loss function: 3.960, Average Loss: 4.300, avg. samples / sec: 8510.74
Iteration:   2100, Loss function: 3.775, Average Loss: 4.296, avg. samples / sec: 8504.75
Iteration:   2100, Loss function: 4.083, Average Loss: 4.299, avg. samples / sec: 8502.66
Iteration:   2120, Loss function: 4.326, Average Loss: 4.292, avg. samples / sec: 8497.19
Iteration:   2120, Loss function: 3.996, Average Loss: 4.295, avg. samples / sec: 8497.96
:::MLL 1582501666.371 epoch_stop: {"value": null, "metadata": {"epoch_num": 35, "file": "train.py", "lineno": 819}}
:::MLL 1582501666.371 epoch_start: {"value": null, "metadata": {"epoch_num": 36, "file": "train.py", "lineno": 673}}
Iteration:   2140, Loss function: 4.115, Average Loss: 4.291, avg. samples / sec: 8472.24
Iteration:   2140, Loss function: 4.139, Average Loss: 4.290, avg. samples / sec: 8470.78
Iteration:   2160, Loss function: 4.012, Average Loss: 4.285, avg. samples / sec: 8516.25
Iteration:   2160, Loss function: 4.046, Average Loss: 4.285, avg. samples / sec: 8513.61
Iteration:   2180, Loss function: 4.049, Average Loss: 4.281, avg. samples / sec: 8472.96
Iteration:   2180, Loss function: 3.766, Average Loss: 4.281, avg. samples / sec: 8474.56
:::MLL 1582501680.151 epoch_stop: {"value": null, "metadata": {"epoch_num": 36, "file": "train.py", "lineno": 819}}
:::MLL 1582501680.151 epoch_start: {"value": null, "metadata": {"epoch_num": 37, "file": "train.py", "lineno": 673}}
Iteration:   2200, Loss function: 3.893, Average Loss: 4.277, avg. samples / sec: 8510.86
Iteration:   2200, Loss function: 3.786, Average Loss: 4.277, avg. samples / sec: 8507.39
Iteration:   2220, Loss function: 4.250, Average Loss: 4.271, avg. samples / sec: 8490.85
Iteration:   2220, Loss function: 3.878, Average Loss: 4.272, avg. samples / sec: 8488.83
Iteration:   2240, Loss function: 4.162, Average Loss: 4.267, avg. samples / sec: 8439.93
Iteration:   2240, Loss function: 4.180, Average Loss: 4.266, avg. samples / sec: 8436.24
:::MLL 1582501693.997 epoch_stop: {"value": null, "metadata": {"epoch_num": 37, "file": "train.py", "lineno": 819}}
:::MLL 1582501693.997 epoch_start: {"value": null, "metadata": {"epoch_num": 38, "file": "train.py", "lineno": 673}}
Iteration:   2260, Loss function: 4.208, Average Loss: 4.264, avg. samples / sec: 8444.90
Iteration:   2260, Loss function: 4.018, Average Loss: 4.262, avg. samples / sec: 8443.54
Iteration:   2280, Loss function: 4.146, Average Loss: 4.261, avg. samples / sec: 8435.47
Iteration:   2280, Loss function: 4.196, Average Loss: 4.259, avg. samples / sec: 8438.37
Iteration:   2300, Loss function: 4.069, Average Loss: 4.256, avg. samples / sec: 8526.82
Iteration:   2300, Loss function: 4.215, Average Loss: 4.255, avg. samples / sec: 8527.60
Iteration:   2320, Loss function: 3.988, Average Loss: 4.253, avg. samples / sec: 8382.35
Iteration:   2320, Loss function: 4.110, Average Loss: 4.252, avg. samples / sec: 8379.30
:::MLL 1582501707.872 epoch_stop: {"value": null, "metadata": {"epoch_num": 38, "file": "train.py", "lineno": 819}}
:::MLL 1582501707.872 epoch_start: {"value": null, "metadata": {"epoch_num": 39, "file": "train.py", "lineno": 673}}
Iteration:   2340, Loss function: 4.050, Average Loss: 4.248, avg. samples / sec: 8477.41
Iteration:   2340, Loss function: 4.045, Average Loss: 4.248, avg. samples / sec: 8481.31
Iteration:   2360, Loss function: 4.162, Average Loss: 4.243, avg. samples / sec: 8446.52
Iteration:   2360, Loss function: 4.119, Average Loss: 4.242, avg. samples / sec: 8443.38
Iteration:   2380, Loss function: 4.329, Average Loss: 4.241, avg. samples / sec: 8462.66
Iteration:   2380, Loss function: 4.142, Average Loss: 4.240, avg. samples / sec: 8463.57
:::MLL 1582501721.702 epoch_stop: {"value": null, "metadata": {"epoch_num": 39, "file": "train.py", "lineno": 819}}
:::MLL 1582501721.703 epoch_start: {"value": null, "metadata": {"epoch_num": 40, "file": "train.py", "lineno": 673}}
Iteration:   2400, Loss function: 3.809, Average Loss: 4.238, avg. samples / sec: 8489.99
Iteration:   2400, Loss function: 3.771, Average Loss: 4.235, avg. samples / sec: 8491.80
Iteration:   2420, Loss function: 4.139, Average Loss: 4.231, avg. samples / sec: 8473.63
Iteration:   2420, Loss function: 4.060, Average Loss: 4.232, avg. samples / sec: 8466.10
Iteration:   2440, Loss function: 3.757, Average Loss: 4.227, avg. samples / sec: 8547.43
Iteration:   2440, Loss function: 3.770, Average Loss: 4.226, avg. samples / sec: 8538.70
:::MLL 1582501735.711 epoch_stop: {"value": null, "metadata": {"epoch_num": 40, "file": "train.py", "lineno": 819}}
:::MLL 1582501735.711 epoch_start: {"value": null, "metadata": {"epoch_num": 41, "file": "train.py", "lineno": 673}}
Iteration:   2460, Loss function: 3.919, Average Loss: 4.223, avg. samples / sec: 8497.53
Iteration:   2460, Loss function: 3.978, Average Loss: 4.223, avg. samples / sec: 8497.82
Iteration:   2480, Loss function: 3.968, Average Loss: 4.217, avg. samples / sec: 8481.21
Iteration:   2480, Loss function: 3.959, Average Loss: 4.219, avg. samples / sec: 8481.71
Iteration:   2500, Loss function: 3.845, Average Loss: 4.213, avg. samples / sec: 8482.07
Iteration:   2500, Loss function: 3.768, Average Loss: 4.212, avg. samples / sec: 8480.96
:::MLL 1582501749.505 epoch_stop: {"value": null, "metadata": {"epoch_num": 41, "file": "train.py", "lineno": 819}}
:::MLL 1582501749.506 epoch_start: {"value": null, "metadata": {"epoch_num": 42, "file": "train.py", "lineno": 673}}
Iteration:   2520, Loss function: 3.865, Average Loss: 4.207, avg. samples / sec: 8489.00
Iteration:   2520, Loss function: 3.988, Average Loss: 4.205, avg. samples / sec: 8487.44
Iteration:   2540, Loss function: 4.116, Average Loss: 4.202, avg. samples / sec: 8514.13
Iteration:   2540, Loss function: 3.953, Average Loss: 4.203, avg. samples / sec: 8510.54
Iteration:   2560, Loss function: 4.082, Average Loss: 4.197, avg. samples / sec: 8496.31
Iteration:   2560, Loss function: 4.148, Average Loss: 4.200, avg. samples / sec: 8494.05
:::MLL 1582501763.290 epoch_stop: {"value": null, "metadata": {"epoch_num": 42, "file": "train.py", "lineno": 819}}
:::MLL 1582501763.290 epoch_start: {"value": null, "metadata": {"epoch_num": 43, "file": "train.py", "lineno": 673}}
Iteration:   2580, Loss function: 3.906, Average Loss: 4.193, avg. samples / sec: 8478.29
Iteration:   2580, Loss function: 3.973, Average Loss: 4.195, avg. samples / sec: 8477.27
Iteration:   2600, Loss function: 3.864, Average Loss: 4.192, avg. samples / sec: 8451.63
Iteration:   2600, Loss function: 4.091, Average Loss: 4.190, avg. samples / sec: 8447.30
Iteration:   2620, Loss function: 3.816, Average Loss: 4.185, avg. samples / sec: 8472.79
Iteration:   2620, Loss function: 3.819, Average Loss: 4.187, avg. samples / sec: 8472.13
:::MLL 1582501777.132 epoch_stop: {"value": null, "metadata": {"epoch_num": 43, "file": "train.py", "lineno": 819}}
:::MLL 1582501777.132 epoch_start: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 673}}
Iteration:   2640, Loss function: 4.040, Average Loss: 4.183, avg. samples / sec: 8479.95
Iteration:   2640, Loss function: 3.873, Average Loss: 4.181, avg. samples / sec: 8478.06
Iteration:   2660, Loss function: 3.865, Average Loss: 4.179, avg. samples / sec: 8506.42
Iteration:   2660, Loss function: 4.253, Average Loss: 4.176, avg. samples / sec: 8504.29
lr decay step #1
lr decay step #1
:::MLL 1582501786.173 eval_start: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 276}}
Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 6/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Predicting Ended, total time: 3.04 s
8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Predicting Ended, total time: 3.04 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.52s)
DONE (t=2.68s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.16059
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.29852
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.15833
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.03884
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.16995
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.25762
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.17275
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.25338
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.26761
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.06971
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.28321
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.41680
Current AP: 0.16059 AP goal: 0.23000
:::MLL 1582501792.455 eval_accuracy: {"value": 0.16059333801034606, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 389}}
:::MLL 1582501792.459 eval_stop: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 392}}
:::MLL 1582501792.466 block_stop: {"value": null, "metadata": {"first_epoch_num": 33, "file": "train.py", "lineno": 804}}
:::MLL 1582501792.466 block_start: {"value": null, "metadata": {"first_epoch_num": 44, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
Iteration:   2680, Loss function: 3.611, Average Loss: 4.169, avg. samples / sec: 3544.71
Iteration:   2680, Loss function: 3.926, Average Loss: 4.172, avg. samples / sec: 3543.97
:::MLL 1582501797.227 epoch_stop: {"value": null, "metadata": {"epoch_num": 44, "file": "train.py", "lineno": 819}}
:::MLL 1582501797.227 epoch_start: {"value": null, "metadata": {"epoch_num": 45, "file": "train.py", "lineno": 673}}
Iteration:   2700, Loss function: 3.620, Average Loss: 4.160, avg. samples / sec: 8506.54
Iteration:   2700, Loss function: 3.645, Average Loss: 4.160, avg. samples / sec: 8506.58
Iteration:   2720, Loss function: 3.527, Average Loss: 4.148, avg. samples / sec: 8492.43
Iteration:   2720, Loss function: 3.384, Average Loss: 4.148, avg. samples / sec: 8491.86
Iteration:   2740, Loss function: 3.455, Average Loss: 4.136, avg. samples / sec: 8510.83
Iteration:   2740, Loss function: 3.570, Average Loss: 4.136, avg. samples / sec: 8510.58
:::MLL 1582501811.008 epoch_stop: {"value": null, "metadata": {"epoch_num": 45, "file": "train.py", "lineno": 819}}
:::MLL 1582501811.008 epoch_start: {"value": null, "metadata": {"epoch_num": 46, "file": "train.py", "lineno": 673}}
Iteration:   2760, Loss function: 3.364, Average Loss: 4.122, avg. samples / sec: 8470.18
Iteration:   2760, Loss function: 3.476, Average Loss: 4.123, avg. samples / sec: 8470.44
Iteration:   2780, Loss function: 3.326, Average Loss: 4.110, avg. samples / sec: 8507.83
Iteration:   2780, Loss function: 3.421, Average Loss: 4.111, avg. samples / sec: 8506.06
Iteration:   2800, Loss function: 3.434, Average Loss: 4.098, avg. samples / sec: 8441.40
Iteration:   2800, Loss function: 3.428, Average Loss: 4.098, avg. samples / sec: 8424.19
:::MLL 1582501824.823 epoch_stop: {"value": null, "metadata": {"epoch_num": 46, "file": "train.py", "lineno": 819}}
:::MLL 1582501824.824 epoch_start: {"value": null, "metadata": {"epoch_num": 47, "file": "train.py", "lineno": 673}}
Iteration:   2820, Loss function: 3.568, Average Loss: 4.085, avg. samples / sec: 8504.61
Iteration:   2820, Loss function: 3.814, Average Loss: 4.086, avg. samples / sec: 8485.77
Iteration:   2840, Loss function: 3.457, Average Loss: 4.074, avg. samples / sec: 8461.85
Iteration:   2840, Loss function: 3.532, Average Loss: 4.074, avg. samples / sec: 8461.05
Iteration:   2860, Loss function: 3.637, Average Loss: 4.063, avg. samples / sec: 8527.53
Iteration:   2860, Loss function: 3.481, Average Loss: 4.064, avg. samples / sec: 8523.11
:::MLL 1582501838.636 epoch_stop: {"value": null, "metadata": {"epoch_num": 47, "file": "train.py", "lineno": 819}}
:::MLL 1582501838.636 epoch_start: {"value": null, "metadata": {"epoch_num": 48, "file": "train.py", "lineno": 673}}
Iteration:   2880, Loss function: 3.263, Average Loss: 4.052, avg. samples / sec: 8422.98
Iteration:   2880, Loss function: 3.471, Average Loss: 4.050, avg. samples / sec: 8418.98
Iteration:   2900, Loss function: 3.365, Average Loss: 4.040, avg. samples / sec: 8482.73
Iteration:   2900, Loss function: 3.199, Average Loss: 4.038, avg. samples / sec: 8482.52
Iteration:   2920, Loss function: 3.533, Average Loss: 4.029, avg. samples / sec: 8474.43
Iteration:   2920, Loss function: 3.397, Average Loss: 4.027, avg. samples / sec: 8474.79
:::MLL 1582501852.485 epoch_stop: {"value": null, "metadata": {"epoch_num": 48, "file": "train.py", "lineno": 819}}
:::MLL 1582501852.486 epoch_start: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 673}}
Iteration:   2940, Loss function: 3.437, Average Loss: 4.016, avg. samples / sec: 8438.20
Iteration:   2940, Loss function: 3.547, Average Loss: 4.015, avg. samples / sec: 8438.16
Iteration:   2960, Loss function: 3.399, Average Loss: 4.004, avg. samples / sec: 8463.88
Iteration:   2960, Loss function: 3.515, Average Loss: 4.004, avg. samples / sec: 8459.85
Iteration:   2980, Loss function: 3.477, Average Loss: 3.993, avg. samples / sec: 8520.93
Iteration:   2980, Loss function: 3.082, Average Loss: 3.992, avg. samples / sec: 8521.46
:::MLL 1582501866.280 epoch_stop: {"value": null, "metadata": {"epoch_num": 49, "file": "train.py", "lineno": 819}}
:::MLL 1582501866.281 epoch_start: {"value": null, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 673}}
Iteration:   3000, Loss function: 3.400, Average Loss: 3.981, avg. samples / sec: 8400.80
Iteration:   3000, Loss function: 3.501, Average Loss: 3.983, avg. samples / sec: 8397.06
:::MLL 1582501868.144 eval_start: {"value": null, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 276}}
Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Predicting Ended, total time: 3.01 s
8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Predicting Ended, total time: 3.01 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.51s)
DONE (t=0.53s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.83s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.22181
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.38296
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.22605
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.05416
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.23083
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.35849
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.21781
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.31509
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.33111
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.09577
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.35548
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.51690
Current AP: 0.22181 AP goal: 0.23000
:::MLL 1582501874.569 eval_accuracy: {"value": 0.22180727930171942, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 389}}
:::MLL 1582501874.570 eval_stop: {"value": null, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 392}}
:::MLL 1582501874.577 block_stop: {"value": null, "metadata": {"first_epoch_num": 44, "file": "train.py", "lineno": 804}}
:::MLL 1582501874.577 block_start: {"value": null, "metadata": {"first_epoch_num": 50, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
Iteration:   3020, Loss function: 3.289, Average Loss: 3.972, avg. samples / sec: 3509.75
Iteration:   3020, Loss function: 3.201, Average Loss: 3.971, avg. samples / sec: 3509.82
Iteration:   3040, Loss function: 3.309, Average Loss: 3.961, avg. samples / sec: 8508.47
Iteration:   3040, Loss function: 3.495, Average Loss: 3.961, avg. samples / sec: 8508.76
:::MLL 1582501886.531 epoch_stop: {"value": null, "metadata": {"epoch_num": 50, "file": "train.py", "lineno": 819}}
:::MLL 1582501886.531 epoch_start: {"value": null, "metadata": {"epoch_num": 51, "file": "train.py", "lineno": 673}}
Iteration:   3060, Loss function: 3.557, Average Loss: 3.949, avg. samples / sec: 8480.48
Iteration:   3060, Loss function: 3.461, Average Loss: 3.950, avg. samples / sec: 8480.14
Iteration:   3080, Loss function: 3.687, Average Loss: 3.939, avg. samples / sec: 8485.98
Iteration:   3080, Loss function: 3.156, Average Loss: 3.938, avg. samples / sec: 8485.55
Iteration:   3100, Loss function: 3.315, Average Loss: 3.926, avg. samples / sec: 8414.02
Iteration:   3100, Loss function: 3.221, Average Loss: 3.929, avg. samples / sec: 8412.46
:::MLL 1582501900.395 epoch_stop: {"value": null, "metadata": {"epoch_num": 51, "file": "train.py", "lineno": 819}}
:::MLL 1582501900.395 epoch_start: {"value": null, "metadata": {"epoch_num": 52, "file": "train.py", "lineno": 673}}
Iteration:   3120, Loss function: 3.489, Average Loss: 3.917, avg. samples / sec: 8458.21
Iteration:   3120, Loss function: 3.415, Average Loss: 3.916, avg. samples / sec: 8456.09
Iteration:   3140, Loss function: 3.181, Average Loss: 3.908, avg. samples / sec: 8503.63
Iteration:   3140, Loss function: 3.336, Average Loss: 3.906, avg. samples / sec: 8504.17
Iteration:   3160, Loss function: 3.376, Average Loss: 3.898, avg. samples / sec: 8505.56
Iteration:   3160, Loss function: 3.292, Average Loss: 3.896, avg. samples / sec: 8505.98
:::MLL 1582501914.171 epoch_stop: {"value": null, "metadata": {"epoch_num": 52, "file": "train.py", "lineno": 819}}
:::MLL 1582501914.172 epoch_start: {"value": null, "metadata": {"epoch_num": 53, "file": "train.py", "lineno": 673}}
Iteration:   3180, Loss function: 3.348, Average Loss: 3.889, avg. samples / sec: 8493.79
Iteration:   3180, Loss function: 3.490, Average Loss: 3.886, avg. samples / sec: 8493.32
Iteration:   3200, Loss function: 3.274, Average Loss: 3.878, avg. samples / sec: 8458.84
Iteration:   3200, Loss function: 3.375, Average Loss: 3.876, avg. samples / sec: 8458.90
Iteration:   3220, Loss function: 3.314, Average Loss: 3.869, avg. samples / sec: 8473.64
Iteration:   3220, Loss function: 3.654, Average Loss: 3.867, avg. samples / sec: 8474.07
:::MLL 1582501928.249 epoch_stop: {"value": null, "metadata": {"epoch_num": 53, "file": "train.py", "lineno": 819}}
:::MLL 1582501928.249 epoch_start: {"value": null, "metadata": {"epoch_num": 54, "file": "train.py", "lineno": 673}}
Iteration:   3240, Loss function: 3.536, Average Loss: 3.858, avg. samples / sec: 8431.91
Iteration:   3240, Loss function: 3.147, Average Loss: 3.857, avg. samples / sec: 8430.59
Iteration:   3260, Loss function: 3.277, Average Loss: 3.849, avg. samples / sec: 8433.12
Iteration:   3260, Loss function: 3.276, Average Loss: 3.847, avg. samples / sec: 8431.70
Iteration:   3280, Loss function: 3.007, Average Loss: 3.837, avg. samples / sec: 8460.07
Iteration:   3280, Loss function: 3.453, Average Loss: 3.841, avg. samples / sec: 8456.72
:::MLL 1582501942.087 epoch_stop: {"value": null, "metadata": {"epoch_num": 54, "file": "train.py", "lineno": 819}}
:::MLL 1582501942.087 epoch_start: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 673}}
Iteration:   3300, Loss function: 3.162, Average Loss: 3.827, avg. samples / sec: 8494.89
Iteration:   3300, Loss function: 3.424, Average Loss: 3.831, avg. samples / sec: 8491.24
Iteration:   3320, Loss function: 3.449, Average Loss: 3.823, avg. samples / sec: 8496.69
Iteration:   3320, Loss function: 3.236, Average Loss: 3.818, avg. samples / sec: 8491.71
lr decay step #2
lr decay step #2
:::MLL 1582501950.015 eval_start: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 276}}
Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Predicting Ended, total time: 3.00 s
8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Predicting Ended, total time: 3.00 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.48s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
DONE (t=0.49s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.49s)
DONE (t=2.51s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.22577
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.38888
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23046
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.06125
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.23777
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.36246
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.22115
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.32126
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.33761
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.10026
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.36648
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.52150
Current AP: 0.22577 AP goal: 0.23000
:::MLL 1582501956.068 eval_accuracy: {"value": 0.22577414073921612, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 389}}
:::MLL 1582501956.116 eval_stop: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 392}}
:::MLL 1582501956.123 block_stop: {"value": null, "metadata": {"first_epoch_num": 50, "file": "train.py", "lineno": 804}}
:::MLL 1582501956.124 block_start: {"value": null, "metadata": {"first_epoch_num": 55, "epoch_count": 5.457677417154162, "file": "train.py", "lineno": 813}}
Iteration:   3340, Loss function: 3.351, Average Loss: 3.810, avg. samples / sec: 3607.64
Iteration:   3340, Loss function: 3.857, Average Loss: 3.814, avg. samples / sec: 3607.35
:::MLL 1582501962.007 epoch_stop: {"value": null, "metadata": {"epoch_num": 55, "file": "train.py", "lineno": 819}}
:::MLL 1582501962.008 epoch_start: {"value": null, "metadata": {"epoch_num": 56, "file": "train.py", "lineno": 673}}
Iteration:   3360, Loss function: 3.361, Average Loss: 3.803, avg. samples / sec: 8488.78
Iteration:   3360, Loss function: 3.225, Average Loss: 3.800, avg. samples / sec: 8479.37
Iteration:   3380, Loss function: 3.438, Average Loss: 3.790, avg. samples / sec: 8484.06
Iteration:   3380, Loss function: 3.462, Average Loss: 3.793, avg. samples / sec: 8472.34
Iteration:   3400, Loss function: 3.256, Average Loss: 3.781, avg. samples / sec: 8500.58
Iteration:   3400, Loss function: 3.787, Average Loss: 3.784, avg. samples / sec: 8500.88
Iteration:   3420, Loss function: 3.642, Average Loss: 3.771, avg. samples / sec: 8503.74
Iteration:   3420, Loss function: 2.962, Average Loss: 3.775, avg. samples / sec: 8504.25
:::MLL 1582501975.801 epoch_stop: {"value": null, "metadata": {"epoch_num": 56, "file": "train.py", "lineno": 819}}
:::MLL 1582501975.801 epoch_start: {"value": null, "metadata": {"epoch_num": 57, "file": "train.py", "lineno": 673}}
Iteration:   3440, Loss function: 3.290, Average Loss: 3.766, avg. samples / sec: 8447.01
Iteration:   3440, Loss function: 3.183, Average Loss: 3.762, avg. samples / sec: 8443.71
Iteration:   3460, Loss function: 3.368, Average Loss: 3.755, avg. samples / sec: 8466.10
Iteration:   3460, Loss function: 3.463, Average Loss: 3.757, avg. samples / sec: 8463.90
Iteration:   3480, Loss function: 3.345, Average Loss: 3.749, avg. samples / sec: 8457.00
Iteration:   3480, Loss function: 3.318, Average Loss: 3.745, avg. samples / sec: 8456.19
:::MLL 1582501989.650 epoch_stop: {"value": null, "metadata": {"epoch_num": 57, "file": "train.py", "lineno": 819}}
:::MLL 1582501989.650 epoch_start: {"value": null, "metadata": {"epoch_num": 58, "file": "train.py", "lineno": 673}}
Iteration:   3500, Loss function: 3.325, Average Loss: 3.741, avg. samples / sec: 8452.10
Iteration:   3500, Loss function: 3.143, Average Loss: 3.738, avg. samples / sec: 8451.66
Iteration:   3520, Loss function: 3.037, Average Loss: 3.730, avg. samples / sec: 8466.40
Iteration:   3520, Loss function: 3.187, Average Loss: 3.732, avg. samples / sec: 8465.63
Iteration:   3540, Loss function: 3.364, Average Loss: 3.723, avg. samples / sec: 8492.73
Iteration:   3540, Loss function: 3.280, Average Loss: 3.721, avg. samples / sec: 8490.27
:::MLL 1582502003.485 epoch_stop: {"value": null, "metadata": {"epoch_num": 58, "file": "train.py", "lineno": 819}}
:::MLL 1582502003.486 epoch_start: {"value": null, "metadata": {"epoch_num": 59, "file": "train.py", "lineno": 673}}
Iteration:   3560, Loss function: 3.123, Average Loss: 3.713, avg. samples / sec: 8473.37
Iteration:   3560, Loss function: 3.277, Average Loss: 3.713, avg. samples / sec: 8474.95
Iteration:   3580, Loss function: 3.494, Average Loss: 3.706, avg. samples / sec: 8476.23
Iteration:   3580, Loss function: 3.454, Average Loss: 3.705, avg. samples / sec: 8472.61
Iteration:   3600, Loss function: 3.248, Average Loss: 3.698, avg. samples / sec: 8510.86
Iteration:   3600, Loss function: 3.346, Average Loss: 3.697, avg. samples / sec: 8512.66
:::MLL 1582502017.277 epoch_stop: {"value": null, "metadata": {"epoch_num": 59, "file": "train.py", "lineno": 819}}
:::MLL 1582502017.277 epoch_start: {"value": null, "metadata": {"epoch_num": 60, "file": "train.py", "lineno": 673}}
Iteration:   3620, Loss function: 3.304, Average Loss: 3.689, avg. samples / sec: 8488.72
Iteration:   3620, Loss function: 3.246, Average Loss: 3.690, avg. samples / sec: 8486.86
Iteration:   3640, Loss function: 3.275, Average Loss: 3.683, avg. samples / sec: 8467.70
Iteration:   3640, Loss function: 3.092, Average Loss: 3.682, avg. samples / sec: 8467.12
Iteration:   3660, Loss function: 3.157, Average Loss: 3.675, avg. samples / sec: 8525.97
Iteration:   3660, Loss function: 3.651, Average Loss: 3.674, avg. samples / sec: 8525.69
:::MLL 1582502031.079 epoch_stop: {"value": null, "metadata": {"epoch_num": 60, "file": "train.py", "lineno": 819}}
:::MLL 1582502031.080 epoch_start: {"value": null, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 673}}
:::MLL 1582502031.537 eval_start: {"value": null, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 276}}
Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 0/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 1/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 2/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 3/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 4/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 6/8Parsing batch: 5/8Parsing batch: 5/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 6/8Parsing batch: 7/8Parsing batch: 6/8Parsing batch: 7/8Parsing batch: 6/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Predicting Ended, total time: 3.20 s
8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 6/8Parsing batch: 7/8Parsing batch: 6/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Parsing batch: 7/8Predicting Ended, total time: 3.20 s
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
Loading and preparing results...
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.50s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
DONE (t=0.51s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.52s)
DONE (t=2.58s).
Accumulating evaluation results...
DONE (t=0.00s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.23026
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.39337
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.23537
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.05829
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.24068
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.37281
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.22234
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.32303
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.33956
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.09758
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.36797
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.53290
Current AP: 0.23026 AP goal: 0.23000
:::MLL 1582502037.878 eval_accuracy: {"value": 0.23026068452372886, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 389}}
:::MLL 1582502037.906 eval_stop: {"value": null, "metadata": {"epoch_num": 61, "file": "train.py", "lineno": 392}}
:::MLL 1582502037.913 block_stop: {"value": null, "metadata": {"first_epoch_num": 55, "file": "train.py", "lineno": 804}}
:::MLL 1582502038.551 run_stop: {"value": null, "metadata": {"status": "success", "file": "train.py", "lineno": 849}}
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '1', '--lr', '3.1e-3', '--wd', '2e-4', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '1', '--lr', '3.1e-3', '--wd', '2e-4', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '1', '--lr', '3.1e-3', '--wd', '2e-4', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '1', '--lr', '3.1e-3', '--wd', '2e-4', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '1', '--lr', '3.1e-3', '--wd', '2e-4', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '1', '--lr', '3.1e-3', '--wd', '2e-4', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '1', '--lr', '3.1e-3', '--wd', '2e-4', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '1', '--lr', '3.1e-3', '--wd', '2e-4', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
Binding: ['/usr/bin/numactl', '--physcpubind=0-4,40-44', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=0', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '1', '--lr', '3.1e-3', '--wd', '2e-4', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=5-9,45-49', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=1', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '1', '--lr', '3.1e-3', '--wd', '2e-4', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=10-14,50-54', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=2', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '1', '--lr', '3.1e-3', '--wd', '2e-4', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=15-19,55-59', '--membind=0', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=3', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '1', '--lr', '3.1e-3', '--wd', '2e-4', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=20-24,60-64', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=4', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '1', '--lr', '3.1e-3', '--wd', '2e-4', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=25-29,65-69', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=5', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '1', '--lr', '3.1e-3', '--wd', '2e-4', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=30-34,70-74', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=6', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '1', '--lr', '3.1e-3', '--wd', '2e-4', '--use-nvjpeg', '--use-roi-decode']
Binding: ['/usr/bin/numactl', '--physcpubind=35-39,75-79', '--membind=1', '/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '--use-fp16', '--nhwc', '--pad-input', '--jit', '--delay-allreduce', '--opt-loss', '--epochs', '80', '--warmup-factor', '0', '--no-save', '--threshold=0.23', '--data', '/data/coco2017', '--evaluation', '120000', '160000', '180000', '200000', '220000', '240000', '260000', '280000', '--batch-size', '120', '--eval-batch-size', '40', '--warmup', '1250', '--bn-group', '1', '--lr', '3.1e-3', '--wd', '2e-4', '--use-nvjpeg', '--use-roi-decode']
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2020-02-23 11:54:04 PM
RESULT,SINGLE_STAGE_DETECTOR,,898,nvidia,2020-02-23 11:39:06 PM
ENDING TIMING RUN AT 2020-02-23 11:54:04 PM
RESULT,SINGLE_STAGE_DETECTOR,,898,nvidia,2020-02-23 11:39:06 PM
